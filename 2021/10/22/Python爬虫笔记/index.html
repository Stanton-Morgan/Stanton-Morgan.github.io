<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python爬虫笔记 | 慎治の万事屋</title><meta name="keywords" content="Python,Crawler"><meta name="author" content="浮世野指针"><meta name="copyright" content="浮世野指针"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="自学爬虫，整理的笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫笔记">
<meta property="og:url" content="https://stantonjoy.github.io/2021/10/22/Python%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="慎治の万事屋">
<meta property="og:description" content="自学爬虫，整理的笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://stantonjoy.github.io/img/Crawler.jpg">
<meta property="article:published_time" content="2021-10-22T08:58:56.000Z">
<meta property="article:modified_time" content="2022-05-04T10:43:30.848Z">
<meta property="article:author" content="浮世野指针">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Crawler">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://stantonjoy.github.io/img/Crawler.jpg"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="https://stantonjoy.github.io/2021/10/22/Python%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Python爬虫笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-04 18:43:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><!--音乐--><div class="aplayer" data-id="2916766519" data-server="netease" data-type="playlist" data-fixed="true" data-listFolded="false" data-order="random" data-preload="none"></div><link rel="stylesheet" href="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.css"><script src="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fab fa-battle-net"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 其他</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/Crawler.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">慎治の万事屋</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fab fa-battle-net"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 其他</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Python爬虫笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-10-22T08:58:56.000Z" title="发表于 2021-10-22 16:58:56">2021-10-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-04T10:43:30.848Z" title="更新于 2022-05-04 18:43:30">2022-05-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/CS/">CS</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Python爬虫笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>使用requests和bs4爬取新东方作文</h1>
<p>其实这是当时学爬虫的最初动力，爬点范文（doge）<br>
技术路线的学习都记录在下面，深感博客杂乱不完整，试图整理了一遍。</p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetchUrl</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    功能：访问 url 的网页，获取网页内容并返回</span></span><br><span class="line"><span class="string">    参数：目标网页的 url</span></span><br><span class="line"><span class="string">    返回：目标网页的 html 内容</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&#x27;</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    r = requests.get(url, headers=headers)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    <span class="keyword">return</span> r.text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getContent</span>(<span class="params">html</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    功能：解析 HTML 网页，获取新闻的文章内容</span></span><br><span class="line"><span class="string">    参数：html 网页内容</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    new_html = html.replace(<span class="string">&quot;&lt;br&gt;&lt;br&gt;&quot;</span>, <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    bsobj = bs4.BeautifulSoup(new_html, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    <span class="comment"># 获取文章 内容</span></span><br><span class="line">    temp = bsobj.find(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;style_stem-text__3Vgg5&#x27;</span>&#125;)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> temp <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        text = temp.find(<span class="string">&#x27;p&#x27;</span>).get_text()</span><br><span class="line">        <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveFile</span>(<span class="params">content, path, filename</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    功能：将文章内容 content 保存到本地文件中</span></span><br><span class="line"><span class="string">    参数：要保存的内容，路径，文件名</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 如果没有该文件夹，则自动生成</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        os.makedirs(path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path + filename, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPageList</span>(<span class="params">pageUrl</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    功能：获取文章链接列表</span></span><br><span class="line"><span class="string">    参数：文章链接</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    html = fetchUrl(pageUrl)</span><br><span class="line">    bsobj = bs4.BeautifulSoup(html, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    pageList = bsobj.find_all(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;style_question-item-content__zwx24&#x27;</span>&#125;)</span><br><span class="line">    linkList = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> pageList:</span><br><span class="line">        temp = page.find(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">        link = temp[<span class="string">&quot;href&quot;</span>]</span><br><span class="line">        url = <span class="string">&quot;https://liuxue.koolearn.com&quot;</span> + link</span><br><span class="line">        linkList.append(url)</span><br><span class="line">    <span class="keyword">return</span> linkList</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_article</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    功能：爬取网页文章，并保存在 指定目录下</span></span><br><span class="line"><span class="string">    参数：文件保存的根目录</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    path = <span class="string">&quot;D:/TOEFL/Writing/&quot;</span></span><br><span class="line">    baseurl = <span class="string">&quot;https://liuxue.koolearn.com/toefl/write-0-&quot;</span></span><br><span class="line">    suffix = <span class="string">&quot;-0/&quot;</span></span><br><span class="line">    var = <span class="number">997</span></span><br><span class="line">    cnt = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> var &gt;= <span class="number">953</span>:</span><br><span class="line">        page_url = baseurl + <span class="built_in">str</span>(var) + suffix</span><br><span class="line">        articles = getPageList(page_url)</span><br><span class="line">        <span class="keyword">for</span> article <span class="keyword">in</span> articles:</span><br><span class="line">            <span class="comment"># 获取新闻文章内容</span></span><br><span class="line">            html = fetchUrl(article)</span><br><span class="line">            content = getContent(html)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> content <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="comment"># 生成文件名</span></span><br><span class="line">                fileName = <span class="built_in">str</span>(cnt) + <span class="string">&quot;.txt&quot;</span></span><br><span class="line">                saveFile(content, path, fileName)</span><br><span class="line">                cnt += <span class="number">1</span></span><br><span class="line">        var -= <span class="number">11</span></span><br><span class="line">    <span class="keyword">return</span> cnt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cnt = download_article()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;all done!\n&quot;</span> + <span class="built_in">str</span>(cnt))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1>基础知识：http协议与url</h1>
<h2 id="什么是http和https协议："><a class="header-anchor" href="#什么是http和https协议：">¶</a>什么是http和https协议：</h2>
<p>HTTP协议：全称是<code>HyperText Transfer Protocol</code>，中文意思是超文本传输协议，是一种发布和接收HTML页面的方法。服务器端口号是<code>80</code>端口。<br>
HTTPS协议：是HTTP协议的加密版本，在HTTP下加入了SSL层。服务器端口号是<code>443</code>端口。</p>
<p>在浏览器中发送一个http请求的过程：</p>
<ol>
<li>当用户在浏览器的地址栏中输入一个URL并按回车键之后，浏览器会向HTTP服务器发送HTTP请求。HTTP请求主要分为“Get”和“Post”两种方法。</li>
<li>当我们在浏览器输入URL <a target="_blank" rel="noopener" href="http://www.baidu.com">http://www.baidu.com</a> 的时候，浏览器发送一个Request请求去获取 <a target="_blank" rel="noopener" href="http://www.baidu.com">http://www.baidu.com</a> 的html文件，服务器把Response文件对象发送回给浏览器。</li>
<li>浏览器分析Response中的 HTML，发现其中引用了很多其他文件，比如Images文件，CSS文件，JS文件。 浏览器会自动再次发送Request去获取图片，CSS文件，或者JS文件。</li>
<li>当所有的文件都下载成功后，网页会根据HTML语法结构，完整的显示出来了。</li>
</ol>
<h2 id="url详解："><a class="header-anchor" href="#url详解：">¶</a>url详解：</h2>
<p><code>URL</code>是<code>Uniform Resource Locator</code>的简写，统一资源定位符。<br>
一个<code>URL</code>由以下几部分组成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scheme://host:port/path/?query-string=xxx#anchor</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>scheme</strong>：代表的是访问的协议，一般为<code>http</code>或者<code>https</code>以及<code>ftp</code>等。</li>
<li><strong>host</strong>：主机名，域名，比如<code>www.baidu.com</code>。</li>
<li><strong>port</strong>：端口号。当你访问一个网站的时候，浏览器默认使用80端口。</li>
<li><strong>path</strong>：查找路径。比如：<code>www.jianshu.com/trending/now</code>，后面的<code>trending/now</code>就是<code>path</code>。</li>
<li><strong>query-string</strong>：查询字符串，比如：<code>www.baidu.com/s?wd=python</code>，后面的<code>wd=python</code>就是查询字符串。</li>
<li><strong>anchor</strong>：锚点，后台一般不用管，前端用来做页面定位的。</li>
</ul>
<p>==在浏览器中请求一个<code>url</code>，浏览器会对这个url进行一个编码。除英文字母，数字和部分符号外，其他的全部使用百分号+十六进制码值进行编码。==</p>
<h2 id="常用的请求方法："><a class="header-anchor" href="#常用的请求方法：">¶</a>常用的请求方法：</h2>
<p>在<code>Http</code>协议中，定义了八种请求方法。这里介绍两种常用的请求方法，分别是<code>get</code>请求和<code>post</code>请求。</p>
<ol>
<li><code>get</code>请求：一般情况下，只从服务器获取数据下来，并不会对服务器资源产生任何影响的时候会使用<code>get</code>请求。</li>
<li><code>post</code>请求：向服务器发送数据（登录）、上传文件等，会对服务器资源产生影响的时候会使用<code>post</code>请求。<br>
以上是在网站开发中常用的两种方法。并且一般情况下都会遵循使用的原则。但是有的网站和服务器为了做反爬虫机制，也经常会不按常理出牌，有可能一个应该使用<code>get</code>方法的请求就一定要改成<code>post</code>请求，这个要视情况而定。</li>
</ol>
<h2 id="请求头常见参数："><a class="header-anchor" href="#请求头常见参数：">¶</a>请求头常见参数：</h2>
<p>在<code>http</code>协议中，向服务器发送一个请求，数据分为三部分，第一个是把数据放在url中，第二个是把数据放在<code>body</code>中（在<code>post</code>请求中），第三个就是把数据放在<code>head</code>中。这里介绍在网络爬虫中经常会用到的一些请求头参数：</p>
<ol>
<li><code>User-Agent</code>：浏览器名称。这个在网络爬虫中经常会被使用到。请求一个网页的时候，服务器通过这个参数就可以知道这个请求是由哪种浏览器发送的。如果我们是通过爬虫发送请求，那么我们的<code>User-Agent</code>就是<code>Python</code>，这对于那些有反爬虫机制的网站来说，可以轻易的判断你这个请求是爬虫。因此我们要经常设置这个值为一些浏览器的值，来伪装我们的爬虫。</li>
<li><code>Referer</code>：表明当前这个请求是从哪个<code>url</code>过来的。这个一般也可以用来做反爬虫技术。如果不是从指定页面过来的，那么就不做相关的响应。</li>
<li><code>Cookie</code>：<code>http</code>协议是无状态的。也就是同一个人发送了两次请求，服务器没有能力知道这两个请求是否来自同一个人。因此这时候就用<code>cookie</code>来做标识。一般如果想要做登录后才能访问的网站，那么就需要发送<code>cookie</code>信息了。</li>
</ol>
<h2 id="常见响应状态码："><a class="header-anchor" href="#常见响应状态码：">¶</a>常见响应状态码：</h2>
<ol>
<li><code>200</code>：请求正常，服务器正常的返回数据。</li>
<li><code>301</code>：永久重定向。比如在访问<code>www.jingdong.com</code>的时候会重定向到<code>www.jd.com</code>。</li>
<li><code>302</code>：临时重定向。比如在访问一个需要登录的页面的时候，而此时没有登录，那么就会重定向到登录页面。</li>
<li><code>400</code>：请求的<code>url</code>在服务器上找不到。换句话说就是请求<code>url</code>错误。</li>
<li><code>403</code>：服务器拒绝访问，权限不够。</li>
<li><code>500</code>：服务器内部错误。可能是服务器出现<code>bug</code>了。</li>
</ol>
<h1>urllib库</h1>
<p><code>urllib</code>库是<code>Python</code>中一个最基本的网络请求库。可以模拟浏览器的行为，向指定的服务器发送一个请求，并可以保存服务器返回的数据。</p>
<h2 id="urlopen函数："><a class="header-anchor" href="#urlopen函数：">¶</a>urlopen函数：</h2>
<p>在<code>Python3</code>的<code>urllib</code>库中，所有和网络请求相关的方法，都被集到<code>urllib.request</code>模块下面了，以先来看下<code>urlopen</code>函数基本的使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line">resp = request.urlopen(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(resp.read())</span><br></pre></td></tr></table></figure>
<p>实际上，使用浏览器访问百度，右键查看源代码。你会发现，跟我们刚才打印出来的数据是一模一样的。也就是说，上面的三行代码就已经帮我们把百度的首页的全部代码爬下来了。一个基本的url请求对应的python代码真的非常简单。<br>
以下对<code>urlopen</code>函数的进行详细讲解：</p>
<ol>
<li><code>url</code>：请求的url。</li>
<li><code>data</code>：请求的<code>data</code>，如果设置了这个值，那么将变成<code>post</code>请求。</li>
<li>返回值：返回值是一个<code>http.client.HTTPResponse</code>对象，这个对象是一个类文件句柄对象。有<code>read(size)</code>、<code>readline</code>、<code>readlines</code>以及<code>getcode</code>等方法。</li>
</ol>
<h2 id="urlretrieve函数："><a class="header-anchor" href="#urlretrieve函数：">¶</a>urlretrieve函数：</h2>
<p>这个函数可以方便的将网页上的一个文件保存到本地。以下代码可以非常方便的将百度的首页下载到本地：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line">request.urlretrieve(<span class="string">&#x27;http://www.baidu.com/&#x27;</span>,<span class="string">&#x27;baidu.html&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="urlencode函数："><a class="header-anchor" href="#urlencode函数：">¶</a>urlencode函数：</h2>
<p>用浏览器发送请求的时候，==如果url中包含了中文或者其他特殊字符==，那么浏览器会自动的给我们进行编码。而如果使用代码发送请求，那么就必须手动的进行编码，这时候就应该使用<code>urlencode</code>函数来实现。<code>urlencode</code>可以把字典数据转换为<code>URL</code>编码的数据。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line">data = &#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;爬虫基础&#x27;</span>,<span class="string">&#x27;greet&#x27;</span>:<span class="string">&#x27;hello world&#x27;</span>,<span class="string">&#x27;age&#x27;</span>:<span class="number">100</span>&#125;</span><br><span class="line">qs = parse.urlencode(data)</span><br><span class="line"><span class="built_in">print</span>(qs)</span><br></pre></td></tr></table></figure>
<h2 id="parse-qs函数："><a class="header-anchor" href="#parse-qs函数：">¶</a>parse_qs函数：</h2>
<p>可以将经过编码后的url参数进行解码。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line">qs = <span class="string">&quot;name=%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80&amp;greet=hello+world&amp;age=100&quot;</span></span><br><span class="line"><span class="built_in">print</span>(parse.parse_qs(qs))</span><br></pre></td></tr></table></figure>
<h2 id="urlparse和urlsplit："><a class="header-anchor" href="#urlparse和urlsplit：">¶</a>urlparse和urlsplit：</h2>
<p>有时候拿到一个url，想要对这个url中的各个组成部分进行分割，那么这时候就可以使用<code>urlparse</code>或者是<code>urlsplit</code>来进行分割。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,parse</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/s?username=zhiliao&#x27;</span></span><br><span class="line"></span><br><span class="line">result = parse.urlsplit(url)</span><br><span class="line"><span class="comment"># result = parse.urlparse(url)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;scheme:&#x27;</span>,result.scheme)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;netloc:&#x27;</span>,result.netloc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;path:&#x27;</span>,result.path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;query:&#x27;</span>,result.query)</span><br></pre></td></tr></table></figure>
<p><code>urlparse</code>和<code>urlsplit</code>基本上是一模一样的。==唯一不一样的地方是，<code>urlparse</code>里面多了一个<code>params</code>属性，而<code>urlsplit</code>没有这个<code>params</code>属性==。比如有一个<code>url</code>为：<code>url = 'http://www.baidu.com/s;hello?wd=python&amp;username=abc#1'</code>，那么<code>urlparse</code>可以获取到<code>hello</code>，而<code>urlsplit</code>不可以获取到。<code>url</code>中的<code>params</code>也用得比较少。</p>
<h2 id="request-Request类："><a class="header-anchor" href="#request-Request类：">¶</a>request.Request类：</h2>
<p>如果想要在请求的时候增加一些请求头，那么就必须使用<code>request.Request</code>类来实现。比如要增加一个<code>User-Agent</code>，示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line"><span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">req = request.Request(<span class="string">&quot;http://www.baidu.com/&quot;</span>,headers=headers)</span><br><span class="line">resp = request.urlopen(req)</span><br><span class="line"><span class="built_in">print</span>(resp.read())</span><br></pre></td></tr></table></figure>
<h2 id="ProxyHandler处理器（代理设置）"><a class="header-anchor" href="#ProxyHandler处理器（代理设置）">¶</a>ProxyHandler处理器（代理设置）</h2>
<p>很多网站会检测某一段时间某个IP的访问次数(通过流量统计，系统日志等)，如果访问次数多的不像正常人，它会禁止这个IP的访问。<br>
所以我们可以设置一些代理服务器，每隔一段时间换一个代理，就算IP被禁止，依然可以换个IP继续爬取。<br>
urllib中通过ProxyHandler来设置使用代理服务器，下面代码说明如何使用自定义opener来使用代理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个是没有使用代理的</span></span><br><span class="line"><span class="comment"># resp = request.urlopen(&#x27;http://httpbin.org/get&#x27;)</span></span><br><span class="line"><span class="comment"># print(resp.read().decode(&quot;utf-8&quot;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个是使用了代理的</span></span><br><span class="line">handler = request.ProxyHandler(&#123;<span class="string">&quot;http&quot;</span>:<span class="string">&quot;218.66.161.88:31769&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">opener = request.build_opener(handler)</span><br><span class="line">req = request.Request(<span class="string">&quot;http://httpbin.org/ip&quot;</span>)</span><br><span class="line">resp = opener.<span class="built_in">open</span>(req)</span><br><span class="line"><span class="built_in">print</span>(resp.read())</span><br></pre></td></tr></table></figure>
<h2 id="“科学上网”代理"><a class="header-anchor" href="#“科学上网”代理">¶</a>“科学上网”代理</h2>
<p>查看当前使用的代理ip以及开放的端口，开放端口用<code>shodan</code>一般就可以搜到，也可以用<code>nmap</code>去扫描，VPN协议端口有三类，略去</p>
<h1>cookie相关：</h1>
<h2 id="cookie的格式："><a class="header-anchor" href="#cookie的格式：">¶</a>cookie的格式：</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Set-Cookie: NAME=VALUE；Expires/Max-age=DATE；Path=PATH；Domain=DOMAIN_NAME；SECURE</span><br></pre></td></tr></table></figure>
<p>参数意义：</p>
<ul>
<li>NAME：cookie的名字。</li>
<li>VALUE：cookie的值。</li>
<li>Expires：cookie的过期时间。</li>
<li>Path：cookie作用的路径。</li>
<li>Domain：cookie作用的域名。</li>
<li>SECURE：是否只在https协议下起作用。</li>
</ul>
<h2 id="使用cookielib库和HTTPCookieProcessor模拟登录："><a class="header-anchor" href="#使用cookielib库和HTTPCookieProcessor模拟登录：">¶</a>使用cookielib库和HTTPCookieProcessor模拟登录：</h2>
<p>Cookie 是指网站服务器为了辨别用户身份和进行Session跟踪，而储存在用户浏览器上的文本文件，Cookie可以保持登录信息到用户下次与服务器的会话。<br>
这里以人人网为例。人人网中，要访问某个人的主页，必须先登录才能访问，登录说白了就是要有cookie信息。那么如果我们想要用代码的方式访问，就必须要有正确的cookie信息才能访问。<br>
解决方案有两种，第一种是使用浏览器访问，然后将cookie信息复制下来，放到headers中。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;略去&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.renren.com/880151247/profile&#x27;</span></span><br><span class="line"></span><br><span class="line">req = request.Request(url,headers=headers)</span><br><span class="line">resp = request.urlopen(req)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;renren.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(resp.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>但是每次在访问需要cookie的页面都要从浏览器中复制cookie比较麻烦。在Python处理Cookie，一般是通过<code>http.cookiejar</code>模块和<code>urllib模块的HTTPCookieProcessor</code>处理器类一起使用。<code>http.cookiejar</code>模块主要作用是提供用于存储cookie的对象。而<code>HTTPCookieProcessor</code>处理器主要作用是处理这些cookie对象，并构建handler对象。</p>
<h2 id="http-cookiejar模块："><a class="header-anchor" href="#http-cookiejar模块：">¶</a>http.cookiejar模块：</h2>
<p>该模块主要的类有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar。这四个类的作用分别如下：</p>
<ol>
<li>CookieJar：管理HTTP cookie值、存储HTTP请求生成的cookie、向传出的HTTP请求添加cookie的对象。整个cookie都存储在内存中，对CookieJar实例进行垃圾回收后cookie也将丢失。</li>
<li>FileCookieJar (filename,delayload=None,policy=None)：从CookieJar派生而来，用来创建FileCookieJar实例，检索cookie信息并将cookie存储到文件中。filename是存储cookie的文件名。delayload为True时支持延迟访问访问文件，即只有在需要时才读取文件或在文件中存储数据。</li>
<li>MozillaCookieJar (filename,delayload=None,policy=None)：从FileCookieJar派生而来，创建与Mozilla浏览器 cookies.txt兼容的FileCookieJar实例。</li>
<li>LWPCookieJar (filename,delayload=None,policy=None)：从FileCookieJar派生而来，创建与libwww-perl标准的 Set-Cookie3 文件格式兼容的FileCookieJar实例。</li>
</ol>
<h2 id="登录人人网："><a class="header-anchor" href="#登录人人网：">¶</a>登录人人网：</h2>
<p>利用<code>http.cookiejar</code>和<code>request.HTTPCookieProcessor</code>登录人人网。相关示例代码如下：（经测试人人网已经不能这样爬了，仅作一例）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,parse</span><br><span class="line"><span class="keyword">from</span> http.cookiejar <span class="keyword">import</span> CookieJar</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_opener</span>():</span></span><br><span class="line">    cookiejar = CookieJar()</span><br><span class="line">    handler = request.HTTPCookieProcessor(cookiejar)</span><br><span class="line">    opener = request.build_opener(handler)</span><br><span class="line">    <span class="keyword">return</span> opener</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login_renren</span>(<span class="params">opener</span>):</span></span><br><span class="line">    data = &#123;<span class="string">&quot;email&quot;</span>: <span class="string">&quot;970138074@qq.com&quot;</span>, <span class="string">&quot;password&quot;</span>: <span class="string">&quot;pythonspider&quot;</span>&#125;</span><br><span class="line">    data = parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    login_url = <span class="string">&quot;http://www.renren.com/PLogin.do&quot;</span></span><br><span class="line">    req = request.Request(login_url, headers=headers, data=data)</span><br><span class="line">    opener.<span class="built_in">open</span>(req)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visit_profile</span>(<span class="params">opener</span>):</span></span><br><span class="line">    url = <span class="string">&#x27;http://www.renren.com/880151247/profile&#x27;</span></span><br><span class="line">    req = request.Request(url,headers=headers)</span><br><span class="line">    resp = opener.<span class="built_in">open</span>(req)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;renren.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(resp.read().decode(<span class="string">&quot;utf-8&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    opener = get_opener()</span><br><span class="line">    login_renren(opener)</span><br><span class="line">    visit_profile(opener)//同一个opener，存了先前访问的cookie</span><br></pre></td></tr></table></figure>
<h2 id="保存cookie到本地："><a class="header-anchor" href="#保存cookie到本地：">¶</a>保存cookie到本地：</h2>
<p>保存<code>cookie</code>到本地，可以使用<code>cookiejar</code>的<code>save</code>方法，并且需要指定一个文件名：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> http.cookiejar <span class="keyword">import</span> MozillaCookieJar</span><br><span class="line"></span><br><span class="line">cookiejar = MozillaCookieJar(<span class="string">&quot;cookie.txt&quot;</span>)</span><br><span class="line">handler = request.HTTPCookieProcessor(cookiejar)</span><br><span class="line">opener = request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">req = request.Request(<span class="string">&#x27;http://httpbin.org/cookies&#x27;</span>,headers=headers)</span><br><span class="line"></span><br><span class="line">resp = opener.<span class="built_in">open</span>(req)</span><br><span class="line"><span class="built_in">print</span>(resp.read())</span><br><span class="line">cookiejar.save(ignore_discard=<span class="literal">True</span>,ignore_expires=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="从本地加载cookie："><a class="header-anchor" href="#从本地加载cookie：">¶</a>从本地加载cookie：</h2>
<p>从本地加载<code>cookie</code>，需要使用<code>cookiejar</code>的<code>load</code>方法，并且也需要指定方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> http.cookiejar <span class="keyword">import</span> MozillaCookieJar</span><br><span class="line"></span><br><span class="line">cookiejar = MozillaCookieJar(<span class="string">&quot;cookie.txt&quot;</span>)</span><br><span class="line">cookiejar.load(ignore_expires=<span class="literal">True</span>,ignore_discard=<span class="literal">True</span>)</span><br><span class="line">handler = request.HTTPCookieProcessor(cookiejar)</span><br><span class="line">opener = request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">req = request.Request(<span class="string">&#x27;http://httpbin.org/cookies&#x27;</span>,headers=headers)</span><br><span class="line"></span><br><span class="line">resp = opener.<span class="built_in">open</span>(req)</span><br><span class="line"><span class="built_in">print</span>(resp.read())</span><br></pre></td></tr></table></figure>
<h1>requests库</h1>
<p>虽然Python的标准库中 urllib模块已经包含了平常我们使用的大多数功能，但是它的 API 使用起来让人感觉不太好，而 Requests宣传是 “HTTP for Humans”，说明使用更简洁方便。</p>
<h2 id="安装和文档地址："><a class="header-anchor" href="#安装和文档地址：">¶</a>安装和文档地址：</h2>
<p>利用<code>pip</code>可以非常方便的安装：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>
<p>中文文档：<a target="_blank" rel="noopener" href="http://docs.python-requests.org/zh_CN/latest/index.html">http://docs.python-requests.org/zh_CN/latest/index.html</a><br>
github地址：<a target="_blank" rel="noopener" href="https://github.com/requests/requests">https://github.com/requests/requests</a></p>
<h2 id="发送GET请求："><a class="header-anchor" href="#发送GET请求：">¶</a>发送GET请求：</h2>
<ol>
<li>
<p>最简单的发送<code>get</code>请求就是通过<code>requests.get</code>来调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.get(<span class="string">&quot;http://www.baidu.com/&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>添加headers和查询参数：<br>
如果想添加 headers，可以传入headers参数来增加请求头中的headers信息。如果要将参数放在url中传递，可以利用 params 参数。相关示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">   </span><br><span class="line">kw = &#123;<span class="string">&#x27;wd&#x27;</span>:<span class="string">&#x27;中国&#x27;</span>&#125;</span><br><span class="line">   </span><br><span class="line">headers = &#123;<span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&quot;</span>&#125;</span><br><span class="line">   </span><br><span class="line"><span class="comment"># params 接收一个字典或者字符串的查询参数，字典类型自动转换为url编码，不需要urlencode()</span></span><br><span class="line">response = requests.get(<span class="string">&quot;http://www.baidu.com/s&quot;</span>, params = kw, headers = headers)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># 查看响应内容，response.text 返回的是Unicode格式的数据</span></span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># 查看响应内容，response.content返回的字节流数据</span></span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># 查看完整url地址</span></span><br><span class="line"><span class="built_in">print</span>(response.url)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># 查看响应头部字符编码</span></span><br><span class="line"><span class="built_in">print</span>(response.encoding)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># 查看响应码</span></span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="发送POST请求："><a class="header-anchor" href="#发送POST请求：">¶</a>发送POST请求：</h2>
<ol>
<li>
<p>最基本的POST请求可以使用<code>post</code>方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.post(<span class="string">&quot;http://www.baidu.com/&quot;</span>,data=data)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>传入data数据：<br>
这时候就不要再使用<code>urlencode</code>进行编码了，直接传入一个字典进去就可以了。比如请求拉勾网的数据的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">   </span><br><span class="line">url = <span class="string">&quot;https://www.lagou.com/jobs/positionAjax.json?city=%E6%B7%B1%E5%9C%B3&amp;needAddtionalResult=false&amp;isSchoolJob=0&quot;</span></span><br><span class="line">   </span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://www.lagou.com/jobs/list_python?labelWords=&amp;fromSearch=true&amp;suginput=&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;first&#x27;</span>: <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;pn&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;kd&#x27;</span>: <span class="string">&#x27;python&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">resp = requests.post(url,headers=headers,data=data)</span><br><span class="line"><span class="comment"># 如果是json数据，直接可以调用json方法</span></span><br><span class="line"><span class="built_in">print</span>(resp.json())</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="使用代理："><a class="header-anchor" href="#使用代理：">¶</a>使用代理：</h2>
<p>使用<code>requests</code>添加代理也非常简单，只要在请求的方法中（比如<code>get</code>或者<code>post</code>）传递<code>proxies</code>参数就可以了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://httpbin.org/get&quot;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">proxy = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;171.14.209.180:27829&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resp = requests.get(url,headers=headers,proxies=proxy)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;xx.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(resp.text)</span><br></pre></td></tr></table></figure>
<h2 id="cookie："><a class="header-anchor" href="#cookie：">¶</a>cookie：</h2>
<p>如果在一个响应中包含了<code>cookie</code>，那么可以利用<code>cookies</code>属性拿到这个返回的<code>cookie</code>值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.renren.com/PLogin.do&quot;</span></span><br><span class="line">data = &#123;<span class="string">&quot;email&quot;</span>:<span class="string">&quot;970138074@qq.com&quot;</span>,<span class="string">&#x27;password&#x27;</span>:<span class="string">&quot;pythonspider&quot;</span>&#125;</span><br><span class="line">resp = requests.get(<span class="string">&#x27;http://www.baidu.com/&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(resp.cookies)</span><br><span class="line"><span class="built_in">print</span>(resp.cookies.get_dict())</span><br></pre></td></tr></table></figure>
<h2 id="session："><a class="header-anchor" href="#session：">¶</a>session：</h2>
<p>之前使用<code>urllib</code>库，是可以使用<code>opener</code>发送多个请求，多个请求之间是可以共享<code>cookie</code>的。那么如果使用<code>requests</code>，也要达到共享<code>cookie</code>的目的，那么可以使用<code>requests</code>库给我们提供的<code>session</code>对象。注意，这里的<code>session</code>不是web开发中的那个session，这个地方只是一个会话的对象而已。还是以登录人人网为例，使用<code>requests</code>来实现。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.renren.com/PLogin.do&quot;</span></span><br><span class="line">data = &#123;<span class="string">&quot;email&quot;</span>:<span class="string">&quot;970138074@qq.com&quot;</span>,<span class="string">&#x27;password&#x27;</span>:<span class="string">&quot;pythonspider&quot;</span>&#125;</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 登录</span></span><br><span class="line">session = requests.session()</span><br><span class="line">session.post(url,data=data,headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问大鹏个人中心</span></span><br><span class="line">resp = session.get(<span class="string">&#x27;http://www.renren.com/880151247/profile&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure>
<h2 id="处理不信任的SSL证书："><a class="header-anchor" href="#处理不信任的SSL证书：">¶</a>处理不信任的SSL证书：</h2>
<p>对于那些已经被信任的SSL证书的网站，比如<code>https://www.baidu.com/</code>，那么使用<code>requests</code>直接就可以正常的返回响应。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">resp = requests.get(<span class="string">&#x27;http://www.12306.cn/mormhweb/&#x27;</span>,verify=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(resp.content.decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>
<h1>XPath语法和lxml模块</h1>
<h2 id="什么是XPath？"><a class="header-anchor" href="#什么是XPath？">¶</a>什么是XPath？</h2>
<p>xpath（XML Path Language）是一门在XML和HTML文档中查找信息的语言，可用来在XML和HTML文档中对元素和属性进行遍历。</p>
<h2 id="XPath语法"><a class="header-anchor" href="#XPath语法">¶</a>XPath语法</h2>
<h3 id="选取节点："><a class="header-anchor" href="#选取节点：">¶</a>选取节点：</h3>
<p>XPath 使用路径表达式来选取 XML 文档中的节点或者节点集。这些路径表达式和我们在常规的电脑文件系统中看到的表达式非常相似。</p>
<table>
<thead>
<tr>
<th>表达式</th>
<th>描述</th>
<th>示例</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>nodename</td>
<td>选取此节点的所有子节点</td>
<td>bookstore</td>
<td>选取bookstore下所有的子节点</td>
</tr>
<tr>
<td>/</td>
<td>如果是在最前面，代表从根节点选取。否则选择某节点下的某个节点</td>
<td>/bookstore</td>
<td>选取根元素下所有的bookstore节点</td>
</tr>
<tr>
<td>//</td>
<td>从全局节点中选择节点，随便在哪个位置</td>
<td>//book</td>
<td>从全局节点中找到所有的book节点</td>
</tr>
<tr>
<td>@</td>
<td>选取某个节点的属性</td>
<td>//book[@price]</td>
<td>选择所有拥有price属性的book节点</td>
</tr>
<tr>
<td>.</td>
<td>当前节点</td>
<td>./a</td>
<td>选取当前节点下的a标签</td>
</tr>
</tbody>
</table>
<h3 id="谓语："><a class="header-anchor" href="#谓语：">¶</a>谓语：</h3>
<p>谓语用来查找某个特定的节点或者包含某个指定的值的节点，被嵌在方括号中。<br>
在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果：</p>
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore/book[1]</td>
<td>选取bookstore下的第一个子元素</td>
</tr>
<tr>
<td>/bookstore/book[last()]</td>
<td>选取bookstore下的倒数第二个book元素。</td>
</tr>
<tr>
<td>bookstore/book[position()&lt;3]</td>
<td>选取bookstore下前面两个子元素。</td>
</tr>
<tr>
<td>//book[@price]</td>
<td>选取拥有price属性的book元素</td>
</tr>
<tr>
<td>//book[@price=10]</td>
<td>选取所有属性price等于10的book元素</td>
</tr>
</tbody>
</table>
<h3 id="通配符"><a class="header-anchor" href="#通配符">¶</a>通配符</h3>
<p>*表示通配符。</p>
<table>
<thead>
<tr>
<th style="text-align:left">通配符</th>
<th style="text-align:left">描述</th>
<th style="text-align:left">示例</th>
<th style="text-align:left">结果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">*</td>
<td style="text-align:left">匹配任意节点</td>
<td style="text-align:left">/bookstore/*</td>
<td style="text-align:left">选取bookstore下的所有子元素。</td>
</tr>
<tr>
<td style="text-align:left">@*</td>
<td style="text-align:left">匹配节点中的任何属性</td>
<td style="text-align:left">//book[@*]</td>
<td style="text-align:left">选取所有带有属性的book元素。</td>
</tr>
</tbody>
</table>
<h3 id="选取多个路径："><a class="header-anchor" href="#选取多个路径：">¶</a>选取多个路径：</h3>
<p>通过在路径表达式中使用“|”运算符，可以选取若干个路径。<br>
示例如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//bookstore/book | //book/title</span><br><span class="line"># 选取所有book元素以及book元素下所有的title元素</span><br></pre></td></tr></table></figure>
<h2 id="lxml库"><a class="header-anchor" href="#lxml库">¶</a>lxml库</h2>
<p>lxml 是 一个HTML/XML的解析器，主要的功能是如何解析和提取 HTML/XML 数据。</p>
<p>lxml和正则一样，也是用 C 实现的，是一款高性能的 Python HTML/XML 解析器，我们可以利用之前学习的XPath语法，来快速的定位特定元素以及节点信息。</p>
<p>需要安装C语言库，可使用 pip 安装：<code>pip install lxml</code></p>
<h3 id="基本使用："><a class="header-anchor" href="#基本使用：">¶</a>基本使用：</h3>
<p>我们可以利用他来解析HTML代码，并且在解析HTML代码的时候，如果HTML代码不规范，他会自动的进行补全。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 lxml 的 etree 库</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree </span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">    &lt;ul&gt;</span></span><br><span class="line"><span class="string">         &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class=&quot;item-inactive&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;third item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt; # 注意，此处缺少一个 &lt;/li&gt; 闭合标签</span></span><br><span class="line"><span class="string">     &lt;/ul&gt;</span></span><br><span class="line"><span class="string"> &lt;/div&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#利用etree.HTML，将字符串解析为HTML文档</span></span><br><span class="line">html = etree.HTML(text) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 按字符串序列化HTML文档</span></span><br><span class="line">result = etree.tostring(html) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>输入结果如下：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-0&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link1.html&quot;</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-1&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link2.html&quot;</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-inactive&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link3.html&quot;</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-1&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link4.html&quot;</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-0&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link5.html&quot;</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以看到。lxml会自动修改HTML代码。例子中不仅补全了li标签，还添加了body，html标签。</p>
<h3 id="从文件中读取html代码："><a class="header-anchor" href="#从文件中读取html代码：">¶</a>从文件中读取html代码：</h3>
<p>除了直接使用字符串进行解析，lxml还支持从文件中读取内容。我们新建一个hello.html文件：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hello.html --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-0&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link1.html&quot;</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-1&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link2.html&quot;</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-inactive&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link3.html&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;bold&quot;</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-1&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link4.html&quot;</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-0&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;link5.html&quot;</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>然后利用<code>etree.parse()</code>方法来读取文件。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取外部文件 hello.html</span></span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line">result = etree.tostring(html, pretty_print=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>输入结果和之前是相同的。</p>
<h3 id="在lxml中使用XPath语法："><a class="header-anchor" href="#在lxml中使用XPath语法：">¶</a>在lxml中使用XPath语法：</h3>
<ol>
<li>
<p>获取所有li标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(html)  <span class="comment"># 显示etree.parse() 返回类型</span></span><br><span class="line">   </span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># 打印&lt;li&gt;标签的元素集合</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>获取所有li元素下的所有class属性的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li/@class&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>获取li标签下href为<code>www.baidu.com</code>的a标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li/a[@href=&quot;www.baidu.com&quot;]&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>获取li标签下所有span标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"><span class="comment">#result = html.xpath(&#x27;//li/span&#x27;)</span></span><br><span class="line"><span class="comment">#注意这么写是不对的：</span></span><br><span class="line"><span class="comment">#因为 / 是用来获取子元素的，而 &lt;span&gt; 并不是 &lt;li&gt; 的子元素，所以，要用双斜杠</span></span><br><span class="line">   </span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li//span&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>获取li标签下的a标签里的所有class：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li/a//@class&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>获取最后一个li的a的href属性对应的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line">   </span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[last()]/a/@href&#x27;</span>)</span><br><span class="line"><span class="comment"># 谓语 [last()] 可以找到最后一个元素</span></span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>获取倒数第二个li元素的内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[last()-1]/a&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># text 方法可以获取元素内容</span></span><br><span class="line"><span class="built_in">print</span>(result[<span class="number">0</span>].text)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>获取倒数第二个li元素的内容的第二种方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">&#x27;hello.html&#x27;</span>)</span><br><span class="line">result = html.xpath(<span class="string">&#x27;//li[last()-1]/a/text()&#x27;</span>)</span><br><span class="line">   </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="BeautifulSoup4库"><a class="header-anchor" href="#BeautifulSoup4库">¶</a>BeautifulSoup4库</h2>
<p>使用流程：</p>
<ol>
<li>根据标签名进行获取节点</li>
<li>获取文本内容和属性</li>
</ol>
<h3 id="属性"><a class="header-anchor" href="#属性">¶</a>属性</h3>
<blockquote>
<p>soup.a.attrs   返回一字典，里面是所有属性和值<br>
soup.a[‘href’] 获取href属性</p>
</blockquote>
<h3 id="文本"><a class="header-anchor" href="#文本">¶</a>文本</h3>
<blockquote>
<p><strong>soup.a.string</strong><br>
<strong>soup.a.text</strong><br>
<strong>soup.a.get_text()</strong><br>
【注】当标签里面还有标签的时候，string获取的为None，其他两个获取纯文本内容</p>
</blockquote>
<h4 id="find方法"><a class="header-anchor" href="#find方法">¶</a>find方法</h4>
<blockquote>
<p><strong>soup.find(‘a’)</strong><br>
<strong>soup.find(‘a’, class_=‘xxx’)</strong><br>
<strong>soup.find(‘a’, title=‘xxx’)</strong><br>
<strong>soup.find(‘a’, id=‘xxx’)</strong><br>
<strong>soup.find(‘a’, id=re.compile(r’xxx’))</strong><br>
【注】find只能找到符合要求的第一个标签，他返回的是一个对象</p>
</blockquote>
<h3 id="find-all方法"><a class="header-anchor" href="#find-all方法">¶</a>find_all方法</h3>
<blockquote>
<p>返回一个列表，列表里面是所有的符合要求的对象<br>
<strong>soup.find_all(‘a’)</strong><br>
<strong>soup.find_all(‘a’, class_=‘wang’)</strong><br>
<strong>soup.find_all(‘a’, id=re.compile(r’xxx’))</strong><br>
<strong>soup.find_all(‘a’, limit=2)</strong>   提取出前两个符合要求的a</p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">浮世野指针</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://stantonjoy.github.io/2021/10/22/Python%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/">https://stantonjoy.github.io/2021/10/22/Python%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://stantonjoy.github.io" target="_blank">慎治の万事屋</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/Crawler/">Crawler</a></div><div class="post_share"><div class="social-share" data-image="/img/Crawler.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/12/17/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"><img class="prev-cover" src="/img/Science.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">记一次完整的渗透测试</div></div></a></div><div class="next-post pull-right"><a href="/2021/10/15/ALU%20Reflection/"><img class="next-cover" src="/img/Science.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">ALU Reflection</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">浮世野指针</div><div class="author-info__description">真正的闲暇并不是说什么也不做，而是能够自由地做自己感兴趣的事情。——Bernard Shaw</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Stanton-Morgan" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1377060711@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">いらしゃいませ（欢迎~）</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">使用requests和bs4爬取新东方作文</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">基础知识：http协议与url</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFhttp%E5%92%8Chttps%E5%8D%8F%E8%AE%AE%EF%BC%9A"><span class="toc-number">2.1.</span> <span class="toc-text">什么是http和https协议：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#url%E8%AF%A6%E8%A7%A3%EF%BC%9A"><span class="toc-number">2.2.</span> <span class="toc-text">url详解：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="toc-number">2.3.</span> <span class="toc-text">常用的请求方法：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E6%B1%82%E5%A4%B4%E5%B8%B8%E8%A7%81%E5%8F%82%E6%95%B0%EF%BC%9A"><span class="toc-number">2.4.</span> <span class="toc-text">请求头常见参数：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E5%93%8D%E5%BA%94%E7%8A%B6%E6%80%81%E7%A0%81%EF%BC%9A"><span class="toc-number">2.5.</span> <span class="toc-text">常见响应状态码：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">urllib库</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#urlopen%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="toc-number">3.1.</span> <span class="toc-text">urlopen函数：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#urlretrieve%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="toc-number">3.2.</span> <span class="toc-text">urlretrieve函数：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#urlencode%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="toc-number">3.3.</span> <span class="toc-text">urlencode函数：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#parse-qs%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="toc-number">3.4.</span> <span class="toc-text">parse_qs函数：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#urlparse%E5%92%8Curlsplit%EF%BC%9A"><span class="toc-number">3.5.</span> <span class="toc-text">urlparse和urlsplit：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#request-Request%E7%B1%BB%EF%BC%9A"><span class="toc-number">3.6.</span> <span class="toc-text">request.Request类：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ProxyHandler%E5%A4%84%E7%90%86%E5%99%A8%EF%BC%88%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE%EF%BC%89"><span class="toc-number">3.7.</span> <span class="toc-text">ProxyHandler处理器（代理设置）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%80%9C%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E2%80%9D%E4%BB%A3%E7%90%86"><span class="toc-number">3.8.</span> <span class="toc-text">“科学上网”代理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">cookie相关：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#cookie%E7%9A%84%E6%A0%BC%E5%BC%8F%EF%BC%9A"><span class="toc-number">4.1.</span> <span class="toc-text">cookie的格式：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8cookielib%E5%BA%93%E5%92%8CHTTPCookieProcessor%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%EF%BC%9A"><span class="toc-number">4.2.</span> <span class="toc-text">使用cookielib库和HTTPCookieProcessor模拟登录：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#http-cookiejar%E6%A8%A1%E5%9D%97%EF%BC%9A"><span class="toc-number">4.3.</span> <span class="toc-text">http.cookiejar模块：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%99%BB%E5%BD%95%E4%BA%BA%E4%BA%BA%E7%BD%91%EF%BC%9A"><span class="toc-number">4.4.</span> <span class="toc-text">登录人人网：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98cookie%E5%88%B0%E6%9C%AC%E5%9C%B0%EF%BC%9A"><span class="toc-number">4.5.</span> <span class="toc-text">保存cookie到本地：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8E%E6%9C%AC%E5%9C%B0%E5%8A%A0%E8%BD%BDcookie%EF%BC%9A"><span class="toc-number">4.6.</span> <span class="toc-text">从本地加载cookie：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">requests库</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%92%8C%E6%96%87%E6%A1%A3%E5%9C%B0%E5%9D%80%EF%BC%9A"><span class="toc-number">5.1.</span> <span class="toc-text">安装和文档地址：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%91%E9%80%81GET%E8%AF%B7%E6%B1%82%EF%BC%9A"><span class="toc-number">5.2.</span> <span class="toc-text">发送GET请求：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%91%E9%80%81POST%E8%AF%B7%E6%B1%82%EF%BC%9A"><span class="toc-number">5.3.</span> <span class="toc-text">发送POST请求：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86%EF%BC%9A"><span class="toc-number">5.4.</span> <span class="toc-text">使用代理：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#cookie%EF%BC%9A"><span class="toc-number">5.5.</span> <span class="toc-text">cookie：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#session%EF%BC%9A"><span class="toc-number">5.6.</span> <span class="toc-text">session：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E4%B8%8D%E4%BF%A1%E4%BB%BB%E7%9A%84SSL%E8%AF%81%E4%B9%A6%EF%BC%9A"><span class="toc-number">5.7.</span> <span class="toc-text">处理不信任的SSL证书：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">XPath语法和lxml模块</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFXPath%EF%BC%9F"><span class="toc-number">6.1.</span> <span class="toc-text">什么是XPath？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#XPath%E8%AF%AD%E6%B3%95"><span class="toc-number">6.2.</span> <span class="toc-text">XPath语法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E5%8F%96%E8%8A%82%E7%82%B9%EF%BC%9A"><span class="toc-number">6.2.1.</span> <span class="toc-text">选取节点：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%93%E8%AF%AD%EF%BC%9A"><span class="toc-number">6.2.2.</span> <span class="toc-text">谓语：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E9%85%8D%E7%AC%A6"><span class="toc-number">6.2.3.</span> <span class="toc-text">通配符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E5%8F%96%E5%A4%9A%E4%B8%AA%E8%B7%AF%E5%BE%84%EF%BC%9A"><span class="toc-number">6.2.4.</span> <span class="toc-text">选取多个路径：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lxml%E5%BA%93"><span class="toc-number">6.3.</span> <span class="toc-text">lxml库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%EF%BC%9A"><span class="toc-number">6.3.1.</span> <span class="toc-text">基本使用：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E6%96%87%E4%BB%B6%E4%B8%AD%E8%AF%BB%E5%8F%96html%E4%BB%A3%E7%A0%81%EF%BC%9A"><span class="toc-number">6.3.2.</span> <span class="toc-text">从文件中读取html代码：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8lxml%E4%B8%AD%E4%BD%BF%E7%94%A8XPath%E8%AF%AD%E6%B3%95%EF%BC%9A"><span class="toc-number">6.3.3.</span> <span class="toc-text">在lxml中使用XPath语法：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup4%E5%BA%93"><span class="toc-number">6.4.</span> <span class="toc-text">BeautifulSoup4库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%9E%E6%80%A7"><span class="toc-number">6.4.1.</span> <span class="toc-text">属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%9C%AC"><span class="toc-number">6.4.2.</span> <span class="toc-text">文本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#find%E6%96%B9%E6%B3%95"><span class="toc-number">6.4.2.1.</span> <span class="toc-text">find方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#find-all%E6%96%B9%E6%B3%95"><span class="toc-number">6.4.3.</span> <span class="toc-text">find_all方法</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/12/24/Christmas%20Eve/" title="Christmas Eve"><img src="/img/Reading.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Christmas Eve"/></a><div class="content"><a class="title" href="/2022/12/24/Christmas%20Eve/" title="Christmas Eve">Christmas Eve</a><time datetime="2022-12-23T17:33:25.000Z" title="发表于 2022-12-24 01:33:25">2022-12-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/25/ORANGE'S-3.2/" title="保护模式-2"><img src="/img/Science.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="保护模式-2"/></a><div class="content"><a class="title" href="/2022/11/25/ORANGE'S-3.2/" title="保护模式-2">保护模式-2</a><time datetime="2022-11-25T14:25:25.000Z" title="发表于 2022-11-25 22:25:25">2022-11-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/23/ORANGE'S-3.1/" title="保护模式-1"><img src="/img/Science.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="保护模式-1"/></a><div class="content"><a class="title" href="/2022/11/23/ORANGE'S-3.1/" title="保护模式-1">保护模式-1</a><time datetime="2022-11-23T14:25:25.000Z" title="发表于 2022-11-23 22:25:25">2022-11-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/23/ORANGE'S-7/" title="IO系统"><img src="/img/Science.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="IO系统"/></a><div class="content"><a class="title" href="/2022/11/23/ORANGE'S-7/" title="IO系统">IO系统</a><time datetime="2022-11-23T14:25:25.000Z" title="发表于 2022-11-23 22:25:25">2022-11-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/14/OSLab2/" title="OSLab2"><img src="/img/Science.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OSLab2"/></a><div class="content"><a class="title" href="/2022/11/14/OSLab2/" title="OSLab2">OSLab2</a><time datetime="2022-11-14T02:33:25.000Z" title="发表于 2022-11-14 10:33:25">2022-11-14</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/Crawler.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 浮世野指针</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><div class="aplayer" data-id="2916766519" data-server="netease" data-type="playlist" data-fixed="true" data-listFolded="false" data-order="random" data-preload="none"></div><link rel="stylesheet" href="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.css"><script src="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":200,"height":267},"mobile":{"show":true},"log":false});</script></body></html>